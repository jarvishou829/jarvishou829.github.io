<!DOCTYPE HTML>
<html>
    <head>
        <title>Haitao Lin's Homepage</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=1000">
        <link rel="stylesheet" href="https://use.typekit.net/quv7bsd.css"> <!-- fonts -->
        <link rel="stylesheet" href="style.css" />

        <script>
             (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
             (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
             m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
             })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
             ga('create', 'UA-89797207-1', 'auto');
             ga('send', 'pageview');
       </script>
    </head>
    <body id="body">
        <div id="main">
            <header id="header">
                <a href="index.html">HOME</a>&nbsp;&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp;
<!--                <a href="https://real.stanford.edu/">LAB</a>-->
            </header>
            <div id="profile">
                <div id="profile-pic">
                    <img src="resources/images/people/jiawei_hou.jpg">
                    <p>
                        <a href="https://scholar.google.com.hk/citations?user=SZGoHs0AAAAJ&hl=zh-CN">Google Scholar</a>
                    </p>
                </div>
                <div id="profile-intro">
                    <div id="profile-name">Jiawei Hou</div>
                    <p style="text-align:justify; text-justify:inter-ideograph;">
                        I’m a third-year PhD student majoring in Computer Science at <a href="https://faet.fudan.edu.cn">School of Computer Science</a>, Fudan University, Shanghai, China.
                        I am advised by Prof.<a href="https://faculty.fudan.edu.cn/xyxue/zh_CN/index.htm">Xiangyang Xue</a> and co-advised by Prof.<a href="http://yanweifu.github.io">Yanwei Fu</a> and Prof.<a href="https://istbi.fudan.edu.cn/info/1774/4911.htm">Taiping Zeng</a>.
                        Prior to this, I received my bachelor’s degree in School of Computer Science from Tianjin University in June 2021.
                        <br />
                        <br />
                        I'm presently working on Robotics, Scene Representation, and 3D Computer Vision. Previously, I worked on perception and simultaneous localization and mapping for autonomous driving.
                        <br />
                    </p>
                    <p>
                        Email: jwhou23@m.fudan.edu.cn <br>
                    </p>
                </div>
                <div style="clear: both;"></div>
            </div>


            <div class="divider"></div>
            <div class="section research">
                <h1>Publications</h1>
                <h3> * denotes equal contribution</h3>

                <div class="research-proj">
                    <a href="https://jarvishou829.github.io/LOP-Field/" class="research-thumb">
                    <!-- <img src="resources/images/projects/ICCV2023_pourit.gif" alt="" /> -->
                    </a>


                    <a href="https://jarvishou829.github.io/LOP-Field/" class="research-proj-title">  LOP-Field: Brain-inspired Layout-Object-Position Fields for Robotic Scene Understanding </a>
                    <p> <strong>Jiawei Hou</strong>, Wenhao Guan, Xiangyang Xue, Taiping Zeng. <br>
                       <!-- ICCV, 2023 <br> -->
                       <a href="https://jarvishou829.github.io/LOP-Field/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <!-- <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_PourIt_Weakly-Supervised_Liquid_Perception_from_a_Single_Image_for_Visual_ICCV_2023_paper.pdf">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp; -->
                       <a href="https://github.com/jarvishou829/LOP-Field">Code </a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <!-- <a href="https://drive.google.com/drive/folders/1j3uIlCxFFMGply-gi-Wt26b-ivZFqpRr?usp=share_link">Dataset </a> -->
                    </p>
                    <p> <br> </p>
                </div>

                <!-- <div class="research-proj">
                    <a href="https://hetolin.github.io/SAR-Net/" class="research-thumb">
                    <img src="resources/images/projects/CVPR2022_sarnet.gif" alt="" />
                    </a>


                    <a href="https://hetolin.github.io/SAR-Net/" class="research-proj-title">  SAR-Net: Shape Alignment and Recovery Network for Category-level 6D Object Pose and Size Estimation </a>
                    <p> <strong>Haitao Lin</strong>, Zichang Liu, Chilam Cheang, Yanwei Fu, Guodong Guo, Xiangyang Xue <br>
                       CVPR, 2022 <br>
                       <a href="https://hetolin.github.io/SAR-Net/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SAR-Net_Shape_Alignment_and_Recovery_Network_for_Category-Level_6D_Object_CVPR_2022_paper.pdf">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://github.com/hetolin/SAR-Net">Code </a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://hetolin.github.io/Skt_grasp/" class="research-thumb">
                    <img src="resources/images/projects/ICRA2022_sktgrasp.gif" alt="" />
                    </a>

                    <a href="https://hetolin.github.io/Skt_grasp/" class="research-proj-title">  I Know What You Draw: Learning Grasp Detection Conditioned on a Few Freehand Sketches </a>
                    <p> <strong>Haitao Lin</strong>, Chilam Cheang, Yanwei Fu, Xiangyang Xue <br>
                       ICRA, 2022 <br>
                       <a href="https://hetolin.github.io/Skt_grasp/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/pdf/2205.04026.pdf">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href=" ">Code </a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://hetolin.github.io/Skt_grasp/" class="research-thumb">
                    <img src="resources/images/projects/ICRA2023_eyegaze.gif" alt="" />
                    </a>

                    <a href="https://hetolin.github.io/Skt_grasp/" class="research-proj-title">  I Know What You Want: A "Smart Bartender" System by Interactive Gaze Following </a>
                    <p> <strong>Haitao Lin</strong>, Zhida Ge, Xiang Li, Yanwei Fu, and Xiangyang Xue  <br>
                       ICRA, Stand Alone Video, 2023 <br>
                       <a href="https://www.youtube.com/watch?v=zumlLDaXfMg">Demo</a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://sunqiang85.github.io/FLarG/" class="research-thumb">
                    <img src="resources/images/projects/IROS2023_flarg.jpg" alt="" />
                    </a>

                    <a href="https://sunqiang85.github.io/FLarG/" class="research-proj-title">  Language Guided Robotic Grasping with Fine-grained Instructions  </a>
                    <p>
                        Qiang Sun*, <strong>Haitao Lin</strong>*, Ying Fu, Yanwei Fu, Xiangyang Xue
                       <br>
                       IROS, 2023 <br>
                       <a href="https://sunqiang85.github.io/FLarG/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://sunqiang85.github.io/FLarG/">Code </a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://baboon527.github.io/lang_6d/" class="research-thumb">
                    <img src="resources/images/projects/ICRA2022_langrasp.gif" alt="" />
                    </a>

                    <a href="https://baboon527.github.io/lang_6d/" class="research-proj-title">  Learning 6-DoF Object Poses to Grasp Category-level Objects by Language Instructions </a>
                    <p>
                       Chilam Cheang, <strong>Haitao Lin</strong>, Yanwei Fu, Xiangyang Xue
                       <br>
                       ICRA, 2022 <br>
                       <a href="https://baboon527.github.io/lang_6d/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/pdf/2205.04028.pdf">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href=" ">Code </a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://jiashunwang.github.io/Neural-Pose-Transfer/" class="research-thumb">
                    <img src="resources/images/projects/CVPR2020_neuralpose.jpg" alt="" />
                    </a>

                    <a href="https://jiashunwang.github.io/Neural-Pose-Transfer/" class="research-proj-title">  Neural Pose Transfer by Spatially Adaptive Instance Normalization  </a>
                    <p>
                        Jiashun Wang*, Chao Wen*, Yanwei Fu, <strong>Haitao Lin</strong>, Tianyun Zou, Xiangyang Xue, Yinda Zhang
                       <br>
                       CVPR, 2020 <br>
                       <a href="https://jiashunwang.github.io/Neural-Pose-Transfer/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Neural_Pose_Transfer_by_Spatially_Adaptive_Instance_Normalization_CVPR_2020_paper.pdf">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://github.com/jiashunwang/Neural-Pose-Transfer/">Code </a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Huo_GeoVLN_Learning_Geometry-Enhanced_Visual_Representation_With_Slot_Attention_for_Vision-and-Language_CVPR_2023_paper.pdf" class="research-thumb">
                    <img src="resources/images/projects/CVPR2023_geovln.png" alt="" />
                    </a>

                    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Huo_GeoVLN_Learning_Geometry-Enhanced_Visual_Representation_With_Slot_Attention_for_Vision-and-Language_CVPR_2023_paper.pdf" class="research-proj-title">  GeoVLN: Learning Geometry-Enhanced Visual Representation with Slot Attention for Vision-and-Language Navigation  </a>
                    <p>
                        Jingyang Huo*, Qiang Sun*, Boyan Jiang*, <strong>Haitao Lin</strong>, Yanwei Fu
                       <br>
                       CVPR, 2023 <br>
                       <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Huo_GeoVLN_Learning_Geometry-Enhanced_Visual_Representation_With_Slot_Attention_for_Vision-and-Language_CVPR_2023_paper.pdf">Paper</a>
                    </p>
                </div>

                <div style="clear: both;"></div> -->

                <!-- <h1>Internship</h1>


                <div class="research-proj">
                    <a href="https://www.mech-mind.com.cn" class="research-thumb">
                       <img src="resources/images/intern/intern_mechmind.png" alt="" />
                    </a>

                    <p>
                    <a href="https://www.mech-mind.com.cn"  class="research-proj-title"> Deep Learning Algorithm and Software Group </a>
                    <br>
                        Computer Vision Algorithm Intern<br>
                    2023 <br>
                    </p>
                </div> -->


                <!-- <h1>Projects</h1>

                <div class="research-proj">
                    <a class="research-thumb">
                        <video playsinline="" muted="" autoplay="" loop="" width="180px">
                        <source src="resources/images/projects/project_nucleic_acid.mp4" type="video/mp4">
                        </video>
                    </a>

                    <p>
                    <a class="research-proj-title"> Hybrid Visual and Tactile-Guided Nucleic Acid Throat Swab Sampling Robot</a>
                    <br>
                        The robotic arm is controlled to gently swab the throat with real-time visual and tactile feedback <br>
                    2022 <br>
                    </p>
                </div>

                <div class="research-proj">
                    <a class="research-thumb">
                        <video playsinline="" muted="" autoplay="" loop="" width="180px">
                        <source src="resources/images/projects/project_fetch_medicine.mp4" type="video/mp4">
                        </video>
                    </a>

                    <p>
                    <a class="research-proj-title"> Robot Pharmacist</a>
                    <br>
                        The robotic arm is controlled to fetch bottles with the estimated 6-DoF pose<br>
                    2021 <br>
                    </p>
                </div>

                <div class="research-proj">
                    <a class="research-thumb">
                        <video playsinline="" muted="" autoplay="" loop="" width="180px">
                        <source src="resources/images/projects/project_legged_robot.mp4" type="video/mp4">
                        </video>
                    </a>

                    <p>
                    <a class="research-proj-title">  Legged robot on Webots Simulation</a>
                    <br>
                        Trotting gait planning and attitude control of a legged robot<br>
                    2019 <br>
                    </p>
                </div>

                <div class="research-proj">
                    <a class="research-thumb">
                        <video playsinline="" muted="" autoplay="" loop="" width="180px">
                        <source src="resources/images/projects/project_fire_detection.mp4" type="video/mp4">
                        </video>
                    </a>

                    <p>
                    <a class="research-proj-title"> Indoor Fire Detection by a Quadcopter</a>
                    <br>
                        Obtain the video stream from DJI Mavic Pro's camera and perform the fire detection algorithm on a mobile phone<br>
                    2018 <br>
                    </p>
                </div>

                <div class="research-proj">
                    <a class="research-thumb">
                        <video playsinline="" muted="" autoplay="" loop="" width="180px">
                        <source src="resources/images/projects/project_quadcopter.mp4" type="video/mp4">
                        </video>
                    </a>

                    <p>
                    <a class="research-proj-title"> DIY Quadcopter</a>
                    <br>
                        A quadcopter is controlled using optical flow for position and an ultrasonic sensor for altitude<br>
                    2016 - 2017 <br>
                    </p>
                </div>

                <div class="research-proj">
                    <a class="research-thumb">
                        <video playsinline="" muted="" autoplay="" loop="" width="180px">
                        <source src="resources/images/projects/project_remote_quadcopter.mp4" type="video/mp4">
                        </video>
                    </a>

                    <p>
                    <a class="research-proj-title"> DIY Quadcopter</a>
                    <br>
                        My DIY quadcopter is flying<br>
                    2015 <br>
                    </p>
                </div> -->

            </div>

        </div>

        <script>
            function toggleNews() {
              var moreNews = document.getElementById("moreNews");
              var moreNewsBtn = document.getElementById("moreNewsBtn");
              var lessNewsBtn = document.getElementById("lessNewsBtn");
              if (moreNewsBtn.style.display === "none") {
                moreNews.style.display = "none";
                moreNewsBtn.style.display = "inline";
                lessNewsBtn.style.display = "none";
              } else {
                moreNews.style.display = "inline";
                moreNewsBtn.style.display = "none";
                lessNewsBtn.style.display = "inline";
              }
            }


            function toggleTalks() {
              var moreTalks = document.getElementById("moreTalks");
              var moreTalksBtn = document.getElementById("moreTalksBtn");
              var lessTalksBtn = document.getElementById("lessTalksBtn");

              if (moreTalksBtn.style.display === "none") {
                moreTalks.style.display = "none";
                moreTalksBtn.style.display = "inline";
                lessTalksBtn.style.display = "none";
              } else {
                moreTalks.style.display = "inline";
                moreTalksBtn.style.display = "none";
                lessTalksBtn.style.display = "inline";
              }
            }
            function togglePubs() {
              var morePubs = document.getElementById("morePubs");
              var morePubsBtn = document.getElementById("morePubsBtn");
              var lessPubsBtn = document.getElementById("lessPubsBtn");
              if (morePubsBtn.style.display === "none") {
                morePubs.style.display = "none";
                morePubsBtn.style.display = "inline";
                lessPubsBtn.style.display = "none";
              } else {
                morePubs.style.display = "inline";
                morePubsBtn.style.display = "none";
                lessPubsBtn.style.display = "inline";
              }
            }

            function showRep() {
              var repBtn = document.getElementById("repBtn");
              var showAllBtn = document.getElementById("showAllBtn");
              repBtn.style.color = "#49bf9d";
              repBtn.style.borderBottom = "1px solid #a4dfce";
              showAllBtn.style.color = "#191e3f";
              showAllBtn.style.borderBottom = "none";
              var  = document.getElementsByClassName("");
              for (var i = 0; i < .length; i++) {
                .item(i).style.display = "none";
              }
            }

            function hideRep() {
              var repBtn = document.getElementById("repBtn");
              var showAllBtn = document.getElementById("showAllBtn");
              repBtn.style.color = "#191e3f";
              repBtn.style.borderBottom = "none";
              showAllBtn.style.color = "#49bf9d";
              showAllBtn.style.borderBottom = "1px solid #a4dfce";
              var  = document.getElementsByClassName("");
              for (var i = 0; i < .length; i++) {
                .item(i).style.display = "table";
              }
            }
        </script>
    </body>
</html>